// AI Service Layer - Handles LLM API calls with Robust Mock/Offline Fallbacks
import type { LLMConfig, StudentState, GameEvent, EventChoice, GameDate, Course } from '../types';

// Generate unique ID
const generateId = () => Math.random().toString(36).substring(2, 9);

const withTimeout = (promise: Promise<any>, ms: number) => {
    return Promise.race([
        promise,
        new Promise((_, reject) => setTimeout(() => reject(new Error(`LLM API Timeout (${ms / 1000}s)`)), ms))
    ]);
};

// Mock Events for Offline Mode
const MOCK_EVENTS = [
    {
        title: "å›¾ä¹¦é¦†çš„å®é™",
        description: "å‘¨æœ«ä½ é€‰æ‹©åœ¨å­¦æ ¡çš„å›¾ä¹¦é¦†åº¦è¿‡ã€‚é˜³å…‰æ´’åœ¨ä¹¦é¡µä¸Šï¼Œå‘¨å›´åªæœ‰ç¿»ä¹¦çš„æ²™æ²™å£°ã€‚ä½ æ„Ÿè§‰è‡ªå·±æ²‰æµ¸åœ¨çŸ¥è¯†çš„æµ·æ´‹ä¸­ã€‚",
        choices: [
            { text: "ä¸“æ³¨å¤ä¹ ä¸“ä¸šè¯¾", effects: { iq: 2, stamina: -5, gpa: 0.1 } },
            { text: "é˜…è¯»ä¸€äº›è¯¾å¤–è¯»ç‰©", effects: { eq: 1, stamina: 5 } }
        ]
    },
    {
        title: "é£Ÿå ‚çš„æ–°èœå¼",
        description: "é£Ÿå ‚äºŒæ¥¼ä»Šå¤©æ¨å‡ºäº†'ç‰¹è‰²åˆ›æ–°æ–™ç†'ã€‚è™½ç„¶çœ‹èµ·æ¥é¢œè‰²æœ‰ç‚¹å¥‡æ€ªï¼Œä½†é—»èµ·æ¥å±…ç„¶è¿˜ä¸é”™ã€‚ä½ çš„è‚šå­é¥¿å¾—å’•å’•å«ã€‚",
        choices: [
            { text: "å‹‡æ•¢å°è¯•æ–°å£å‘³", effects: { stamina: 10, luck: 2 } },
            { text: "è¿˜æ˜¯åƒå›è€ä¸‰æ ·", effects: { stamina: 5, money: -15 } }
        ]
    },
    {
        title: "å®¿èˆæ¥¼ä¸‹çš„å¶é‡",
        description: "æ™šè¯¾å›æ¥ï¼Œä½ åœ¨å®¿èˆæ¥¼ä¸‹å¶é‡äº†å¾ˆä¹…æ²¡è§çš„åŒå­¦ã€‚taçœ‹èµ·æ¥ä¼¼ä¹æœ‰äº›å¿ƒäº‹ï¼Œæ­£ä¸€ä¸ªäººååœ¨é•¿æ¤…ä¸Šå‘å‘†ã€‚",
        choices: [
            { text: "ä¸»åŠ¨ä¸Šå‰æ‰“æ‹›å‘¼å™æ—§", effects: { eq: 2, charm: 1 } },
            { text: "å½“ä½œæ²¡çœ‹è§ï¼Œå¾„ç›´ä¸Šæ¥¼", effects: { stress: -5 } }
        ]
    },
    {
        title: "çªå¦‚å…¶æ¥çš„é˜µé›¨",
        description: "ä»æ•™å­¦æ¥¼å‡ºæ¥ï¼Œå¤©ç©ºçªç„¶ä¸‹èµ·äº†ä¸€é˜µæ€¥ä¿ƒçš„å¤§é›¨ã€‚ä½ æ²¡æœ‰å¸¦ä¼ï¼Œè€Œæ­¤æ—¶æ­£å¥½çœ‹åˆ°ä¸€ä½æ‹¿ç€å¤§ä¼çš„ç†Ÿäººç»è¿‡ã€‚",
        choices: [
            { text: "åšç€è„¸çš®å»è¹­ä¼", effects: { eq: 1, charm: 1, stamina: -2 } },
            { text: "åœ¨å±‹æªä¸‹ç­‰é›¨åœ", effects: { stamina: -5, stress: 5 } },
            { text: "å†’é›¨è·‘å›å®¿èˆ", effects: { stamina: -15, luck: -1 } }
        ]
    },
    {
        title: "æ ¡å›­ç¤¾å›¢æ‹›æ–°",
        description: "è·¯è¿‡å­¦ç”Ÿæ´»åŠ¨ä¸­å¿ƒï¼Œé‚£é‡Œæ­£çƒ­é—¹éå‡¡åœ°è¿›è¡Œç€ç¤¾å›¢æ‹›æ˜Ÿã€‚äº”èŠ±å…«é—¨çš„æ‹›ç‰Œè®©ä½ ç›®ä¸æš‡æ¥ï¼Œå„ç§å­¦é•¿å­¦å§åœ¨çƒ­æƒ…æ‹‰å®¢ã€‚",
        choices: [
            { text: "å¡«è¡¨ç”³è¯·å¿ƒä»ªçš„ç¤¾å›¢", effects: { eq: 2, money: -50 } },
            { text: "åªçœ‹çƒ­é—¹ï¼Œä¸ä¸ºæ‰€åŠ¨", effects: { stamina: 5 } }
        ]
    }
];

// Generate dynamic event based on student state (Synchronous version)
export const generateMockEventSync = (currentDate: GameDate): GameEvent => {
    const mock = MOCK_EVENTS[Math.floor(Math.random() * MOCK_EVENTS.length)];

    const choices: EventChoice[] = mock.choices.map((c, idx) => ({
        id: `choice_${idx}`,
        text: c.text,
        effects: Object.entries(c.effects).map(([key, val]) => {
            if (key === 'gpa') return { type: 'gpa' as const, target: 'gpa', value: val as number };
            if (key === 'money') return { type: 'money' as const, target: 'money', value: val as number };
            return { type: 'attribute' as const, target: key, value: val as number };
        }),
    }));

    return {
        id: `mock_${generateId()}`,
        type: 'dynamic',
        title: mock.title,
        description: mock.description,
        choices,
        isLLMGenerated: true, // We mark as true to satisfy GameEvent type requirements for dynamic events
        timestamp: currentDate,
    };
};

// Generate dynamic event based on student state (Promise wrapper for legacy compatibility)
export const generateMockEvent = (currentDate: GameDate): GameEvent => {
    return generateMockEventSync(currentDate);
};

// Format game state for LLM context
const formatGameContext = (student: StudentState): string => {
    const { attributes, academic, money, npcs, flags, currentDate } = student;
    const semesterStr = currentDate.semester === 1 ? 'ç§‹å­£' : 'æ˜¥å­£';

    return `
Current Student Status:
- Name: ${student.name}, Year ${currentDate.year}, ${semesterStr} Semester, Week ${currentDate.week}
- University: ${academic.universityName} (${academic.universityTier})
- Major: ${academic.major.name}
- GPA: ${academic.gpa.toFixed(2)}
- Money: Â¥${money}
- IQ: ${attributes.iq}, EQ: ${attributes.eq}
- Energy: ${attributes.stamina}%, Stress: ${attributes.stress}%
- Charm: ${attributes.charm}, Luck: ${attributes.luck}
- Dating: ${flags.isDating ? 'Yes' : 'No'}
- Has Job: ${flags.hasJob ? 'Yes' : 'No'}
- Relationships: ${npcs.slice(0, 3).map(n => `${n.name}(${n.role}:${n.relationshipScore})`).join(', ')}
`.trim();
};

const SYSTEM_PROMPT = `You are the narrator of a Chinese university life simulator game. 
Your role is to generate engaging, realistic, and sometimes humorous campus events.
Response format (JSON only): { "title": "...", "description": "...", "choices": [...] }`;

// Parse LLM response to GameEvent
const parseEventResponse = (
    response: string,
    currentDate: GameDate
): GameEvent | null => {
    try {
        let jsonStr = response;
        const jsonMatch = response.match(/```(?:json)?\s*([\s\S]*?)```/);
        if (jsonMatch) jsonStr = jsonMatch[1];

        const data = JSON.parse(jsonStr.trim());
        const choices: EventChoice[] = data.choices.map((c: any, idx: number) => ({
            id: `choice_${idx}`,
            text: c.text,
            effects: Object.entries(c.effects || {}).map(([key, val]) => {
                if (key === 'gpa') return { type: 'gpa' as const, target: 'gpa', value: val as number };
                if (key === 'money') return { type: 'money' as const, target: 'money', value: val as number };
                return { type: 'attribute' as const, target: key, value: val as number };
            }),
        }));

        return {
            id: generateId(),
            type: 'dynamic',
            title: data.title || 'æ ¡å›­äº‹ä»¶',
            description: data.description || 'å‘ç”Ÿäº†ä¸€äº›äº‹æƒ…...',
            choices,
            isLLMGenerated: true,
            timestamp: currentDate,
        };
    } catch (error) {
        console.error('Failed to parse LLM response:', error);
        return null;
    }
};

// Main API call function
export const callLLM = async (
    config: LLMConfig,
    systemPrompt: string,
    userPrompt: string
): Promise<string> => {
    const { provider, apiKey, baseUrl, model, maxTokens, temperature } = config;
    if (!apiKey) throw new Error('API Key is missing');

    let endpoint: string;
    let headers: Record<string, string> = { 'Content-Type': 'application/json' };
    let body: Record<string, unknown>;

    switch (provider) {
        case 'openai':
        case 'custom': // Custom provider uses OpenAI-compatible format
            // Robust base URL handling: trim trailing slashes and ensure /chat/completions is present
            {
                const base = (baseUrl || 'https://api.openai.com/v1').replace(/\/+$/, '');
                endpoint = `${base}/chat/completions`;
                headers['Authorization'] = `Bearer ${apiKey}`;
                body = { model, messages: [{ role: 'system', content: systemPrompt }, { role: 'user', content: userPrompt }], max_tokens: maxTokens, temperature };
            }
            break;
        case 'gemini':
            endpoint = baseUrl || `https://generativelanguage.googleapis.com/v1beta/models/${model}:generateContent?key=${apiKey}`;
            body = { contents: [{ parts: [{ text: `${systemPrompt}\n\n${userPrompt}` }] }], generationConfig: { maxOutputTokens: maxTokens, temperature } };
            break;
        default:
            // Fallback to OpenAI-compatible format for unknown providers
            {
                const fallbackBase = (baseUrl || 'https://api.openai.com/v1').replace(/\/+$/, '');
                endpoint = `${fallbackBase}/chat/completions`;
                headers['Authorization'] = `Bearer ${apiKey}`;
                body = { model, messages: [{ role: 'system', content: systemPrompt }, { role: 'user', content: userPrompt }], max_tokens: maxTokens, temperature };
            }
    }

    const response = await withTimeout(fetch(endpoint, {
        method: 'POST',
        headers,
        body: JSON.stringify(body),
    }), 15000) as Response;

    if (!response.ok) {
        const error = await response.text();
        throw new Error(`LLM API error: ${response.status} - ${error}`);
    }

    const data = await response.json();
    if (provider === 'openai' || provider === 'custom') return data.choices?.[0]?.message?.content || '';
    if (provider === 'gemini') return data.candidates?.[0]?.content?.parts?.[0]?.text || '';
    return data.choices?.[0]?.message?.content || '';
};

// Generate dynamic event with fallback
export const generateDynamicEvent = async (
    config: LLMConfig,
    student: StudentState,
    trigger?: string,
    locationContext?: { name: string; type: string }
): Promise<GameEvent | null> => {
    // 1. HARD SYNC CHECK: If no key, return IMMEDIATELY using Promise.resolve()
    if (!config.apiKey || config.apiKey.trim() === '') {
        console.log("Creating Mock Event (Synchronous Path)");
        return Promise.resolve(generateMockEventSync(student.currentDate));
    }

    const context = formatGameContext(student);

    // NPC Injection
    const randomNpc = student.npcs[Math.floor(Math.random() * student.npcs.length)];
    const npcInjection = randomNpc ? `Involve this NPC if possible: ${randomNpc.name} (${randomNpc.role})` : '';

    let promptTrigger = trigger || '';
    if (locationContext) {
        promptTrigger += `\nCurrent Location: ${locationContext.name} (${locationContext.type}). Generate an event specific to this location.`;
        if (locationContext.type === 'off_campus') promptTrigger += ' (Example: Shopping, Part-time job, City exploration)';
        if (locationContext.type === 'academic') promptTrigger += ' (Example: Study, Research, Competition)';
        if (locationContext.type === 'living') promptTrigger += ' (Example: Relaxing, Socializing, Dorm life)';
    }

    const userPrompt = `${context}\n\n${npcInjection}\n${promptTrigger ? `Trigger/Context: ${promptTrigger}` : 'Generate a random campus event.'}`;

    try {
        const response = await callLLM(config, SYSTEM_PROMPT, userPrompt);
        const event = parseEventResponse(response, student.currentDate);
        return event || generateMockEventSync(student.currentDate);
    } catch (error) {
        console.error('AI Generation Failed, switching to Mock Mode:', error);
        return generateMockEventSync(student.currentDate);
    }
};

// Test LLM connection
export const testLLMConnection = async (config: LLMConfig): Promise<{ success: boolean; error?: string }> => {
    if (!config.apiKey) return { success: false, error: 'è¯·è¾“å…¥ API Key' };

    try {
        const response = await withTimeout(callLLM(
            config,
            'You are a helpful assistant.',
            'Reply with just the word "connected" if you can read this.'
        ), 30000); // 30 second timeout for test
        const success = response.toLowerCase().includes('connected');
        return { success, error: success ? undefined : 'API å“åº”ä¸åŒ¹é…' };
    } catch (error: any) {
        return { success: false, error: error.message || 'è¿æ¥å¤±è´¥' };
    }
};

// ============ Forum LLM Integration ============

const FORUM_SYSTEM_PROMPT = `ä½ æ˜¯ä¸€ä¸ªä¸­å›½å¤§å­¦è®ºå›çš„æ¨¡æ‹Ÿå™¨ã€‚æ ¹æ®å­¦ç”Ÿå½“å‰çš„çŠ¶æ€å’Œæ¸¸æˆæ—¶é—´ï¼Œç”Ÿæˆ3-5æ¡è´´è¿‘ç°å®çš„è®ºå›å¸–å­ã€‚
å¸–å­åº”è¯¥åæ˜ æ ¡å›­ç”Ÿæ´»ã€è€ƒè¯•ã€ç¤¾äº¤ç­‰è¯é¢˜ã€‚å¦‚æœæœ‰å³å°†åˆ°æ¥çš„è€ƒè¯•æˆ–äº‹ä»¶ï¼Œè¦ç”Ÿæˆç›¸å…³çš„å¸–å­ã€‚
è¿”å›JSONæ ¼å¼: { "posts": ["å¸–å­1", "å¸–å­2", ...] }`;

const MOCK_FORUM_POSTS = [
    "å¬è¯´äºŒé£Ÿå ‚çš„çº¢çƒ§è‚‰æ¶¨ä»·äº†ï¼ŒçœŸå®åº¦ 80%...",
    "è¿™å‘¨çš„æ•°å­¦å»ºæ¨¡æ¯”èµ›é¢˜ç›®å¤ªå˜æ€äº†å§ï¼",
    "æ±‚é—®ï¼šå“ªä½æ•™æˆçš„æœŸæœ«è€ƒæ¯”è¾ƒå®¹æ˜“è¿‡ï¼Ÿ",
    "å›¾ä¹¦é¦†å åº§å¤§æˆ˜ï¼Œä»Šå¤©åˆå¤±è´¥äº†...",
    "æœ‰æ²¡æœ‰äººä¸€èµ·ç»„é˜Ÿè€ƒç ”ï¼Ÿ",
];

export interface ForumComment {
    id: string;
    author: string;
    content: string;
    timestamp: number;
}

export interface ForumPost {
    id: string;
    content: string;
    author: string;
    likes: number;
    liked: boolean;
    time: string;
    comments: ForumComment[];
}

export const generateForumPosts = async (
    config: LLMConfig,
    student: StudentState
): Promise<ForumPost[]> => {
    // Generate contextual hints
    const pendingExamNames = student.pendingExams?.map(e => e.name).join(', ') || '';
    const weekInfo = `ç¬¬${student.currentDate.year}å­¦å¹´ ç¬¬${student.currentDate.week}å‘¨`;

    const contextHints = [];
    if (student.currentDate.week >= 16) contextHints.push('æœŸæœ«è€ƒè¯•å‘¨ä¸´è¿‘');
    if (pendingExamNames) contextHints.push(`æœ‰äººæ­£åœ¨å¤‡è€ƒ: ${pendingExamNames}`);
    if (student.currentDate.week === 1) contextHints.push('æ–°å­¦æœŸå¼€å§‹');

    // Randomized author names for forum posts
    const AUTHORS = ['ææ˜', 'ç‹èŠ³', 'å¼ ä¼Ÿ', 'åˆ˜æ´‹', 'é™ˆé™', 'èµµå¼º', 'å­™ä¸½', 'å‘¨æ°', 'å´å¨œ', 'éƒ‘äº‘'];

    // Offline mode fallback
    if (!config.apiKey || config.apiKey.trim() === '') {
        return MOCK_FORUM_POSTS.map((content, i) => ({
            id: `forum_${i}`,
            content,
            author: AUTHORS[Math.floor(Math.random() * AUTHORS.length)],
            likes: Math.floor(Math.random() * 50),
            liked: false,
            time: `${Math.floor(Math.random() * 12) + 1}å°æ—¶å‰`,
            comments: []
        }));
    }

    try {
        const userPrompt = `å½“å‰æ—¶é—´: ${weekInfo}\nèƒŒæ™¯æç¤º: ${contextHints.join('; ') || 'æ™®é€šæ ¡å›­ç”Ÿæ´»'}\n\nè¯·ç”Ÿæˆ5æ¡è®ºå›å¸–å­ã€‚`;
        const response = await callLLM(config, FORUM_SYSTEM_PROMPT, userPrompt);

        let posts: string[] = [];
        try {
            const jsonMatch = response.match(/```(?:json)?\s*([\s\S]*?)```/) || [null, response];
            const data = JSON.parse(jsonMatch[1]?.trim() || response.trim());
            posts = data.posts || [];
        } catch {
            posts = MOCK_FORUM_POSTS;
        }

        return posts.map((content, i) => ({
            id: `forum_${Date.now()}_${i}`,
            content: typeof content === 'string' ? content : String(content),
            author: AUTHORS[Math.floor(Math.random() * AUTHORS.length)],
            likes: Math.floor(Math.random() * 50),
            liked: false,
            time: `${Math.floor(Math.random() * 12) + 1}å°æ—¶å‰`,
            comments: []
        }));
    } catch (error) {
        console.error('Forum LLM failed:', error);
        const AUTHORS = ['ææ˜', 'ç‹èŠ³', 'å¼ ä¼Ÿ', 'åˆ˜æ´‹', 'é™ˆé™', 'èµµå¼º', 'å­™ä¸½', 'å‘¨æ°', 'å´å¨œ', 'éƒ‘äº‘'];
        return MOCK_FORUM_POSTS.map((content, i) => ({
            id: `forum_fallback_${i}`,
            content,
            author: AUTHORS[Math.floor(Math.random() * AUTHORS.length)],
            likes: Math.floor(Math.random() * 20),
            liked: false,
            time: `${Math.floor(Math.random() * 12) + 1}å°æ—¶å‰`,
            comments: []
        }));
    }
};

// ============ WeChat NPC Chat Integration ============

const NPC_CHAT_SYSTEM_PROMPT = `ä½ æ­£åœ¨æ‰®æ¼”ä¸€ä¸ªä¸­å›½å¤§å­¦ç”Ÿæ´»æ¨¡æ‹Ÿæ¸¸æˆä¸­çš„NPCè§’è‰²ã€‚
ä½ çš„ä»»åŠ¡æ˜¯æ ¹æ®NPCçš„æ€§æ ¼å’ŒèƒŒæ™¯ï¼Œç”¨è‡ªç„¶ã€å£è¯­åŒ–çš„ä¸­æ–‡å›å¤ç”¨æˆ·çš„æ¶ˆæ¯ã€‚
å›å¤åº”è¯¥ç®€çŸ­ï¼ˆ1-3å¥è¯ï¼‰ï¼Œç¬¦åˆè§’è‰²è®¾å®šï¼Œå¯ä»¥å¸¦æœ‰è¡¨æƒ…ç¬¦å·ã€‚
ç›´æ¥è¿”å›å›å¤å†…å®¹ï¼Œä¸è¦åŒ…å«ä»»ä½•JSONæˆ–é¢å¤–æ ¼å¼ã€‚`;

const GAME_ASSISTANT_PROMPT = `ä½ æ˜¯"å¤§å­¦ç”Ÿæ´»æ¨¡æ‹Ÿå™¨"æ¸¸æˆä¸­çš„AIåŠ©æ‰‹ã€‚
ä½ çš„ä»»åŠ¡æ˜¯å¸®åŠ©ç©å®¶äº†è§£æ¸¸æˆæœºåˆ¶ã€ç»™å‡ºå»ºè®®ã€è§£ç­”é—®é¢˜ã€‚
ä½ äº†è§£æ¸¸æˆçš„æ‰€æœ‰ç³»ç»Ÿï¼šè¡ŒåŠ¨åŠ›(æ¯å‘¨7ç‚¹)ã€å±æ€§(IQ/EQ/ä½“åŠ›/å‹åŠ›/é­…åŠ›/è¿æ°”)ã€è¯ä¹¦è€ƒè¯•ã€å…¼èŒå·¥ä½œç­‰ã€‚
ç”¨å‹å¥½ã€ç®€æ´çš„ä¸­æ–‡å›å¤ï¼Œå¯ä»¥å¸¦è¡¨æƒ…ç¬¦å·ã€‚ç›´æ¥è¿”å›å›å¤å†…å®¹ã€‚`;

export const generateNPCReply = async (
    config: LLMConfig,
    npc: { name: string; personality: string; role: string },
    userMessage: string,
    chatHistory: { role: 'user' | 'npc'; content: string }[],
    isGameAssistant: boolean = false
): Promise<string> => {
    const systemPrompt = isGameAssistant ? GAME_ASSISTANT_PROMPT : NPC_CHAT_SYSTEM_PROMPT;

    // Build conversation context
    const historyContext = chatHistory.slice(-6).map(msg =>
        `${msg.role === 'user' ? 'ç©å®¶' : npc.name}: ${msg.content}`
    ).join('\n');

    const userPrompt = isGameAssistant
        ? `${historyContext}\nç©å®¶: ${userMessage}\n\nè¯·å›å¤ç©å®¶çš„é—®é¢˜ã€‚`
        : `NPCä¿¡æ¯:\n- åå­—: ${npc.name}\n- è§’è‰²: ${npc.role}\n- æ€§æ ¼: ${npc.personality}\n\nå¯¹è¯è®°å½•:\n${historyContext}\nç©å®¶: ${userMessage}\n\nè¯·ä»¥${npc.name}çš„èº«ä»½å›å¤ã€‚`;

    // Offline fallback
    if (!config.apiKey || config.apiKey.trim() === '') {
        const fallbacks = isGameAssistant
            ? ['è¿™ä¸ªé—®é¢˜æˆ‘æš‚æ—¶å›ç­”ä¸äº†ï¼Œå»ºè®®ä½ æ¢ç´¢ä¸€ä¸‹æ¸¸æˆï¼ğŸ®', 'è¯•è¯•çœ‹ä¸åŒçš„é€‰æ‹©ï¼Œå¯èƒ½ä¼šæœ‰æƒŠå–œå“¦ï¼âœ¨', 'è®°å¾—ç®¡ç†å¥½ä½ çš„è¡ŒåŠ¨åŠ›å’Œä½“åŠ›ï¼ğŸ’ª']
            : ['å“ˆå“ˆï¼Œä½ è¯´å¾—å¯¹ï¼', 'æœ€è¿‘æ€ä¹ˆæ ·å•Šï¼Ÿ', 'æœ‰ç©ºä¸€èµ·å»é£Ÿå ‚åƒé¥­å§ï¼', 'è€ƒè¯•å¤ä¹ å¾—æ€ä¹ˆæ ·äº†ï¼Ÿ'];
        return fallbacks[Math.floor(Math.random() * fallbacks.length)];
    }

    try {
        const response = await withTimeout(callLLM(config, systemPrompt, userPrompt), 30000); // 30s timeout
        return response.trim() || '...(æ²‰é»˜)';
    } catch (error) {
        console.error('NPC Chat LLM failed:', error);
        return isGameAssistant ? 'æŠ±æ­‰ï¼Œæˆ‘ç°åœ¨æœ‰ç‚¹å¿™ï¼Œç¨åå†èŠï¼' : '...(å¯¹æ–¹ä¼¼ä¹åœ¨å¿™)';
    }
};

/**
 * Generates a proactive message from an NPC to the player.
 * Used when an NPC "decides" to text the player first.
 */
export const generateProactiveMessage = async (
    config: LLMConfig,
    npc: { name: string; personality: string; role: string },
    student: StudentState
): Promise<string> => {
    const { year, semester, week } = student.currentDate;
    const timeInfo = `ç¬¬${year}å­¦å¹´, ${semester === 1 ? 'ä¸Šå­¦æœŸ' : 'ä¸‹å­¦æœŸ'}, ç¬¬${week}å‘¨`;

    const systemPrompt = `ä½ æ­£åœ¨æ‰®æ¼”ä¸€ä¸ªä¸­å›½å¤§å­¦ç”Ÿæ´»æ¨¡æ‹Ÿæ¸¸æˆä¸­çš„NPCè§’è‰²ï¼š${npc.name}ã€‚
ä½ çš„è§’è‰²æ˜¯ç©å®¶çš„${npc.role}ï¼Œæ€§æ ¼æ˜¯${npc.personality}ã€‚
ä½ çš„ä»»åŠ¡æ˜¯ä¸»åŠ¨ç»™ç©å®¶å‘ä¸€æ¡å¾®ä¿¡æ¶ˆæ¯ã€‚æ¶ˆæ¯åº”è¯¥è‡ªç„¶ã€å£è¯­åŒ–ï¼Œåæ˜ å½“å‰çš„æ ¡å›­ç”Ÿæ´»èƒŒæ™¯ã€‚
èƒŒæ™¯æ—¶é—´ï¼š${timeInfo}ã€‚
å¦‚æœæ˜¯å­¦æœŸåˆï¼Œå¯ä»¥é—®å€™å¼€å­¦ï¼›å¦‚æœæ˜¯å­¦æœŸæœ«ï¼Œå¯ä»¥æè€ƒè¯•æˆ–æ”¾å‡ï¼›å¹³æ—¶å¯ä»¥èŠå…«å¦ã€çº¦é¥­æˆ–åˆ†äº«è¶£äº‹ã€‚
å›å¤åº”è¯¥ç®€çŸ­ï¼ˆ1-2å¥ï¼‰ï¼Œç›´æ¥è¿”å›æ¶ˆæ¯å†…å®¹ã€‚`;

    const userPrompt = `ç”±äºç°åœ¨æ˜¯${timeInfo}ï¼Œè¯·ä»¥${npc.name}çš„èº«ä»½ç»™ç©å®¶å‘ä¸€æ¡å¼€åœºç™½ã€‚`;

    if (!config.apiKey || config.apiKey.trim() === '') {
        const fallbacks = [
            'å˜¿ï¼Œæœ€è¿‘åœ¨å¿™ä»€ä¹ˆå‘¢ï¼Ÿ',
            'ä»Šå¤©é£Ÿå ‚çš„é¥­èœä¸é”™ï¼Œè¦ä¸è¦ä¸€èµ·å»ï¼Ÿ',
            'æ„Ÿè§‰è¿™å‘¨çš„è¯¾å¥½ç´¯å•Šï¼Œä½ å‘¢ï¼Ÿ',
            'åˆšæ‰åœ¨å›¾ä¹¦é¦†çœ‹åˆ°ä½ äº†ï¼Œæ„Ÿè§‰ä½ å­¦å¾—å¥½è®¤çœŸï¼',
            'å‘¨æœ«æœ‰ç©ºå—ï¼Ÿæƒ³çº¦ä½ å‡ºå»ç©ã€‚'
        ];
        return fallbacks[Math.floor(Math.random() * fallbacks.length)];
    }

    try {
        const response = await withTimeout(callLLM(config, systemPrompt, userPrompt), 15000);
        return response.trim() || 'æœ€è¿‘æ€ä¹ˆæ ·ï¼Ÿ';
    } catch (error) {
        console.error('Proactive message LLM failed:', error);
        return 'æœ€è¿‘æ€ä¹ˆæ ·ï¼Ÿ';
    }
};

/**
 * Generates a WeChat moment content for an NPC.
 */
export const generateMoment = async (
    config: LLMConfig,
    npc: { name: string; personality: string; role: string },
    gameDate: { year: number; semester: number; week: number }
): Promise<string> => {
    const timeInfo = `ç¬¬${gameDate.year}å­¦å¹´, ${gameDate.semester === 1 ? 'ä¸Šå­¦æœŸ' : 'ä¸‹å­¦æœŸ'}, ç¬¬${gameDate.week}å‘¨`;

    const systemPrompt = `ä½ æ­£åœ¨æ‰®æ¼”ä¸€ä¸ªä¸­å›½å¤§å­¦ç”ŸNPCï¼š${npc.name}ã€‚
è§’è‰²ï¼šç©å®¶çš„${npc.role}ï¼Œæ€§æ ¼ï¼š${npc.personality}ã€‚
ä»»åŠ¡ï¼šå‘ä¸€æ¡å¾®ä¿¡æœ‹å‹åœˆã€‚
è¦æ±‚ï¼š
1. å†…å®¹ç®€çŸ­ï¼ˆ1-3å¥ï¼‰ï¼Œå£è¯­åŒ–ã€‚
2. ç»“åˆå½“å‰æ—¶é—´ï¼ˆ${timeInfo}ï¼‰å’Œæ ¡å›­ç”Ÿæ´»ã€‚
3. å¯ä»¥å¸¦ç‚¹æƒ…ç»ªæˆ–åæ§½ï¼Œæˆ–è€…åˆ†äº«æ—¥å¸¸ç”Ÿæ´»ã€‚
4. ä¸éœ€è¦å¸¦è¯é¢˜æ ‡ç­¾ã€‚
ç›´æ¥è¿”å›æœ‹å‹åœˆæ­£æ–‡å†…å®¹ã€‚`;

    const userPrompt = `è¯·ç”Ÿæˆä¸€æ¡æœ‹å‹åœˆå†…å®¹ã€‚`;

    if (!config.apiKey || config.apiKey.trim() === '') {
        const fallbacks = [
            'ä»Šå¤©å¤©æ°”çœŸä¸é”™ï¼Œé€‚åˆå»å›¾ä¹¦é¦†åˆ·é¢˜ï¼',
            'é£Ÿå ‚çš„éº»è¾£é¦™é”…è¶Šæ¥è¶Šå¥½åƒäº†ï¼Œæ¨èï¼',
            'åˆè¦äº¤ä½œä¸šäº†ï¼Œèµ¶æ­»çº¿ä¸­...',
            'å‘¨æœ«æœ‰æ²¡æœ‰äººä¸€èµ·å»çœ‹ç”µå½±ï¼Ÿ',
            'åˆšè·‘å®Œæ­¥ï¼Œæ„Ÿè§‰æ•´ä¸ªäººéƒ½ç²¾ç¥äº†ã€‚',
            'è¿™å‘¨çš„è¯¾å¥½å¤šå•Šï¼Œæ±‚å®‰æ…°ã€‚'
        ];
        return fallbacks[Math.floor(Math.random() * fallbacks.length)];
    }

    try {
        const response = await withTimeout(callLLM(config, systemPrompt, userPrompt), 15000);
        return response.trim() || 'ä»Šå¤©å¿ƒæƒ…ä¸é”™ï¼';
    } catch (error) {
        console.error('Moment generation LLM failed:', error);
        return 'ä»Šå¤©å¿ƒæƒ…ä¸é”™ï¼';
    }
};
/**
 * Generates a list of courses using LLM based on major and grade.
 */
export const generateLLMCourses = async (
    config: LLMConfig,
    major: { name: string; id: string },
    year: number,
    semester: number,
    count: number
): Promise<Partial<Course>[]> => {
    const semName = semester === 1 ? 'ä¸Šå­¦æœŸ' : 'ä¸‹å­¦æœŸ';
    const yearName = year === 1 ? 'å¤§ä¸€' : year === 2 ? 'å¤§äºŒ' : year === 3 ? 'å¤§ä¸‰' : 'å¤§å››';

    const systemPrompt = `ä½ æ˜¯ä¸€ä¸ªå¤§å­¦æ•™åŠ¡ç³»ç»Ÿæ¨¡æ‹Ÿå™¨ã€‚æ ¹æ®ç»™å®šçš„ä¸“ä¸šå’Œå¹´çº§ï¼Œç”Ÿæˆä¸€ç»„ç¬¦åˆé€»è¾‘çš„ç¡¬æ ¸è¯¾ç¨‹ã€‚
è¿”å›JSONæ ¼å¼: { "courses": [ { "name": "...", "credits": 2-4, "type": "Required/Elective", "statBonus": { "iq": 1-3, ... } } ] }
ç”Ÿæˆçš„æ•°é‡åº”ä¸º: ${count}ã€‚
ä¸“ä¸š: ${major.name}
å¹´çº§: ${yearName}${semName}`;

    if (!config.apiKey || config.apiKey.trim() === '') {
        return []; // Caller handles fallback
    }

    try {
        const response = await withTimeout(callLLM(config, systemPrompt, `è¯·ç”Ÿæˆ ${count} é—¨è¯¾ç¨‹ã€‚`), 20000);
        const jsonMatch = response.match(/```(?:json)?\s*([\s\S]*?)```/) || [null, response];
        const data = JSON.parse(jsonMatch[1]?.trim() || response.trim());
        return data.courses || [];
    } catch (error) {
        console.error('LLM Course generation failed:', error);
        return [];
    }
};

// ============ Game Tasks LLM Generation ============

export interface GameTask {
    id: string;
    title: string;
    description: string;
    type: 'daily' | 'weekly' | 'story';
    priority: 'high' | 'medium' | 'low';
    reward?: string;
}

const MOCK_TASKS: GameTask[] = [
    { id: 'task_1', title: 'å®Œæˆæœ¬å‘¨è¯¾ç¨‹', description: 'å‚åŠ è‡³å°‘3èŠ‚ä¸“ä¸šè¯¾', type: 'weekly', priority: 'high', reward: '+çŸ¥è¯†ç‚¹' },
    { id: 'task_2', title: 'å›¾ä¹¦é¦†è‡ªä¹ ', description: 'å»ä¸€æ¬¡å›¾ä¹¦é¦†å¤ä¹ åŠŸè¯¾', type: 'daily', priority: 'medium', reward: '+IQ' },
    { id: 'task_3', title: 'ç¤¾äº¤æ´»åŠ¨', description: 'ä¸åŒå­¦æˆ–å®¤å‹äº’åŠ¨ä¸€æ¬¡', type: 'daily', priority: 'low', reward: '+EQ' },
];

export const generateGameTasks = async (
    config: LLMConfig,
    student: StudentState
): Promise<GameTask[]> => {
    if (!config.apiKey || config.apiKey.trim() === '') {
        return MOCK_TASKS;
    }

    const systemPrompt = `ä½ æ˜¯ä¸€ä¸ªå¤§å­¦ç”Ÿæ´»æ¨¡æ‹Ÿæ¸¸æˆçš„ä»»åŠ¡ç³»ç»Ÿã€‚æ ¹æ®å­¦ç”Ÿå½“å‰çŠ¶æ€ç”Ÿæˆ3-5ä¸ªæ¸¸æˆä»»åŠ¡ã€‚
è¿”å›JSONæ ¼å¼: { "tasks": [ { "title": "...", "description": "...", "type": "daily/weekly/story", "priority": "high/medium/low", "reward": "+å±æ€§æˆ–å¥–åŠ±æè¿°" } ] }
ä»»åŠ¡ç±»å‹: daily(æ—¥å¸¸), weekly(æœ¬å‘¨), story(å‰§æƒ…)
ä»»åŠ¡åº”ç»“åˆå­¦ç”Ÿå½“å‰çŠ¶æ€ã€å­¦å¹´ã€ä¸“ä¸šæ¥ç”Ÿæˆã€‚`;

    const userPrompt = `å­¦ç”Ÿ: ${student.name}, ç¬¬${student.currentDate.year}å¹´ç¬¬${student.currentDate.week}å‘¨
ä¸“ä¸š: ${student.academic.major.name}
GPA: ${student.academic.gpa.toFixed(2)}
å±æ€§: IQ ${student.attributes.iq}, EQ ${student.attributes.eq}, ä½“åŠ› ${student.attributes.stamina}
è¯·ç”Ÿæˆä»»åŠ¡ã€‚`;

    try {
        const response = await withTimeout(callLLM(config, systemPrompt, userPrompt), 15000);
        const jsonMatch = response.match(/```(?:json)?\s*([\s\S]*?)```/) || [null, response];
        const data = JSON.parse(jsonMatch[1]?.trim() || response.trim());
        return (data.tasks || []).map((t: any) => ({
            id: `task_${generateId()}`,
            title: t.title,
            description: t.description,
            type: t.type || 'daily',
            priority: t.priority || 'medium',
            reward: t.reward
        }));
    } catch (error) {
        console.error('LLM Task generation failed:', error);
        return MOCK_TASKS;
    }
};

// ============ NPC Profile LLM Generation ============

export interface NPCProfile {
    backstory: string;
    hobby: string;
    dream: string;
    secretTrait: string;
    relationshipAdvice: string;
}

const MOCK_PROFILE: NPCProfile = {
    backstory: 'æ¥è‡ªä¸€ä¸ªæ™®é€šå®¶åº­ï¼Œé«˜è€ƒåæ¥åˆ°è¿™æ‰€å¤§å­¦ï¼Œæ¢¦æƒ³ç€èƒ½å¤Ÿæ”¹å˜è‡ªå·±çš„å‘½è¿ã€‚',
    hobby: 'å–œæ¬¢åœ¨é—²æš‡æ—¶é—´çœ‹åŠ¨æ¼«ã€æ‰“æ¸¸æˆï¼Œå¶å°”ä¹Ÿä¼šå»æ“åœºè·‘æ­¥ã€‚',
    dream: 'å¸Œæœ›æ¯•ä¸šåèƒ½æ‰¾åˆ°ä¸€ä»½ç¨³å®šçš„å·¥ä½œï¼Œä¹°æˆ¿ä¹°è½¦ï¼Œè®©çˆ¶æ¯è¿‡ä¸Šå¥½æ—¥å­ã€‚',
    secretTrait: 'è¡¨é¢ä¸Šçœ‹èµ·æ¥å¾ˆå¼€æœ—ï¼Œä½†å…¶å®å†…å¿ƒæœ‰äº›è‡ªå‘ï¼Œå®³æ€•è¢«åˆ«äººçœ‹ä¸èµ·ã€‚',
    relationshipAdvice: 'å¤šå…³å¿ƒtaçš„æƒ…ç»ªå˜åŒ–ï¼Œé€‚å½“é€äº›å°ç¤¼ç‰©å¯ä»¥å¿«é€Ÿæå‡å¥½æ„Ÿåº¦ã€‚'
};

export const generateNPCProfile = async (
    config: LLMConfig,
    npc: { name: string; personality: string; role: string; gender: string },
    student: StudentState
): Promise<NPCProfile> => {
    if (!config.apiKey || config.apiKey.trim() === '') {
        return MOCK_PROFILE;
    }

    const systemPrompt = `ä½ æ˜¯ä¸€ä¸ªå¤§å­¦ç”Ÿæ´»æ¨¡æ‹Ÿæ¸¸æˆçš„è§’è‰²æè¿°ç”Ÿæˆå™¨ã€‚ä¸ºç»™å®šçš„NPCç”Ÿæˆè¯¦ç»†çš„ä¸ªäººèµ„æ–™ã€‚
è¿”å›JSONæ ¼å¼: { 
    "backstory": "è§’è‰²èƒŒæ™¯æ•…äº‹(50-100å­—)", 
    "hobby": "å…´è¶£çˆ±å¥½", 
    "dream": "äººç”Ÿæ¢¦æƒ³", 
    "secretTrait": "éšè—ç‰¹è´¨æˆ–ç§˜å¯†",
    "relationshipAdvice": "æ”»ç•¥è¯¥è§’è‰²çš„å»ºè®®"
}
ç”Ÿæˆçš„å†…å®¹åº”ç¬¦åˆä¸­å›½å¤§å­¦ç”Ÿæ´»åœºæ™¯ï¼Œè¯­è¨€ç”ŸåŠ¨æœ‰è¶£ã€‚`;

    const userPrompt = `è§’è‰²: ${npc.name}
æ€§åˆ«: ${npc.gender === 'male' ? 'ç”·' : 'å¥³'}
èº«ä»½: ${npc.role === 'roommate' ? 'å®¤å‹' : npc.role === 'classmate' ? 'åŒå­¦' : npc.role === 'professor' ? 'æ•™æˆ' : npc.role === 'friend' ? 'æœ‹å‹' : 'å…¶ä»–'}
æ€§æ ¼: ${npc.personality}
ç©å®¶: ${student.name} (${student.academic.major.name}ä¸“ä¸š)
è¯·ç”Ÿæˆè¯¥è§’è‰²çš„è¯¦ç»†èµ„æ–™ã€‚`;

    try {
        const response = await withTimeout(callLLM(config, systemPrompt, userPrompt), 15000);
        const jsonMatch = response.match(/```(?:json)?\s*([\s\S]*?)```/) || [null, response];
        const data = JSON.parse(jsonMatch[1]?.trim() || response.trim());
        return {
            backstory: data.backstory || MOCK_PROFILE.backstory,
            hobby: data.hobby || MOCK_PROFILE.hobby,
            dream: data.dream || MOCK_PROFILE.dream,
            secretTrait: data.secretTrait || MOCK_PROFILE.secretTrait,
            relationshipAdvice: data.relationshipAdvice || MOCK_PROFILE.relationshipAdvice
        };
    } catch (error) {
        console.error('LLM NPC Profile generation failed:', error);
        return MOCK_PROFILE;
    }
};
